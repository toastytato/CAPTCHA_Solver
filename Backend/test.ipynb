{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path: path to folder of images\n",
    "def get_formatted_images(path, cnt):\n",
    "    image_list = []\n",
    "    for idx, file_name in enumerate(glob.glob(path + '/*.png')):\n",
    "        if idx >= cnt:\n",
    "            break\n",
    "\n",
    "        img = np.array(Image.open(file_name))\n",
    "\n",
    "        if len(img.shape) == 2:\n",
    "            print('gray img found')\n",
    "            \n",
    "        h, w, d = img.shape\n",
    "        min_dim = min(h, w)\n",
    "        img = img[0:min_dim, 0:min_dim]\n",
    "\n",
    "        image_list.append(img)\n",
    "    return image_list\n",
    "\n",
    "def get_labels(images, label):\n",
    "    labels = [label] * len(images)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb#ch0000002?line=9'>10</a>\u001b[0m \u001b[39m# bicycle:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb#ch0000002?line=10'>11</a>\u001b[0m images \u001b[39m=\u001b[39m get_formatted_images(path, cnt\u001b[39m=\u001b[39mnum_imgs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb#ch0000002?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(images\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb#ch0000002?line=12'>13</a>\u001b[0m labels \u001b[39m=\u001b[39m get_labels(images, \u001b[39m'\u001b[39m\u001b[39mbicycle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb#ch0000002?line=13'>14</a>\u001b[0m test_images \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from helper import get_formatted_images, get_labels\n",
    "\n",
    "\n",
    "#path = 'G:\\\\My Drive\\\\School\\\\6. Spring 2022\\\\EE379K - COMPUTER VISION\\\\CAPTCHA Solver\\\\archive\\\\Recaptcha Dataset\\\\Bicycle'\n",
    "path = '/Users/andrewwhitaker/Downloads/Recaptcha Dataset/Bicycle'\n",
    "\n",
    "num_imgs = 10\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# bicycle:\n",
    "images = get_formatted_images(path, cnt=num_imgs)\n",
    "print(images.shape)\n",
    "labels = get_labels(images, 'bicycle')\n",
    "test_images = []\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    dim = (100, 100)\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    test_images.append(resized)\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(resized, cmap='gray')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 238399 files belonging to 17 classes.\n",
      "Using 190720 files for training.\n",
      "Found 238399 files belonging to 17 classes.\n",
      "Using 47679 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 100\n",
    "img_width = 100\n",
    "\n",
    "#data_dir = 'G:\\\\My Drive\\\\School\\\\6. Spring 2022\\\\EE379K - COMPUTER VISION\\\\CAPTCHA Solver\\\\archive\\\\Recaptcha Dataset'\n",
    "data_dir = '/Users/andrewwhitaker/Downloads/Recaptcha Dataset/'\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5960/5960 [==============================] - 218s 36ms/step - loss: 6335552512.0000 - accuracy: 0.6995 - val_loss: 19689019392.0000 - val_accuracy: 0.8198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176dc6580>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 49, 49, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 47, 47, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 23, 23, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 21, 21, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 10, 10, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               409728    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 429,765\n",
      "Trainable params: 429,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_2 = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[143 132  96 ...  83  92  97]\n",
      "  [146 143 126 ...  98 113 119]\n",
      "  [161 161 159 ...  99 111 115]\n",
      "  ...\n",
      "  [ 67  57  50 ... 134 139 137]\n",
      "  [ 49  50  53 ... 112 115 111]\n",
      "  [ 53  53  62 ...  92  98 101]]\n",
      "\n",
      " [[137 142 142 ...  62  60  66]\n",
      "  [127 130 134 ...  63  69  72]\n",
      "  [125 126 131 ...  65  66  65]\n",
      "  ...\n",
      "  [213 213 217 ... 115 144 139]\n",
      "  [205 205 200 ...  89 136 156]\n",
      "  [212 205 183 ...  66 103 136]]\n",
      "\n",
      " [[ 58  57  58 ...  63  71 110]\n",
      "  [ 62  64  63 ...  51  56  81]\n",
      "  [ 66  64  62 ...  40  41  48]\n",
      "  ...\n",
      "  [ 52  52  54 ...  64  66  63]\n",
      "  [ 51  53  54 ...  69  66  65]\n",
      "  [ 50  52  53 ...  72  70  71]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 68  67  71 ...  82  56  48]\n",
      "  [ 76  77  77 ...  91  69  65]\n",
      "  [ 64  63  60 ...  87  66  63]\n",
      "  ...\n",
      "  [164 165 166 ... 149 151 152]\n",
      "  [165 165 166 ... 148 151 155]\n",
      "  [166 167 167 ... 147 149 153]]\n",
      "\n",
      " [[ 55  55  54 ...  76  82  94]\n",
      "  [ 68  71  72 ...  68  83  97]\n",
      "  [ 96  97 100 ...  87 107 111]\n",
      "  ...\n",
      "  [158 161 164 ... 137 135 131]\n",
      "  [162 163 162 ... 138 138 134]\n",
      "  [163 160 157 ... 138 139 138]]\n",
      "\n",
      " [[131 131 131 ... 131 131 131]\n",
      "  [131 131 131 ... 131 131 131]\n",
      "  [131 131 131 ... 131 131 131]\n",
      "  ...\n",
      "  [ 43  44  44 ...  45  44  41]\n",
      "  [ 36  33  35 ...  47  44  41]\n",
      "  [ 32  34  34 ...  44  45  45]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_images_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100, 100, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name='rescaling_3_input'), name='rescaling_3_input', description=\"created by layer 'rescaling_3_input'\"), but it was called on an input with incompatible shape (None, 100, 100).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_3\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_9\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 100, 100)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 100, 100), dtype=uint8)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb#ch0000013?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(test_images_2)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb#ch0000013?line=1'>2</a>\u001b[0m score \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msoftmax(predictions[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrewwhitaker/Documents/CAPTCHA_Solver/Backend/test.ipynb#ch0000013?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(score)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/andrewwhitaker/miniforge3/envs/env_tf3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_3\" (type Sequential).\n    \n    Input 0 of layer \"conv2d_9\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 100, 100)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 100, 100), dtype=uint8)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images_2)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d2ac4bba7b60916d19a9de8bad87f6999dbb357b1f58d98d7f9cb67d9de555f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
